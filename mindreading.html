<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Mind-Reader Demo — Webcam + Face Tracking (JS + HTML)</title>
  <style>
    :root{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,'Noto Sans',sans-serif}
    body{margin:12px;background:#0f172a;color:#e6eef8}
    h1{font-size:20px;margin:0 0 8px}
    .wrap{display:grid;grid-template-columns:380px 1fr 260px;gap:12px}
    .card{background:#0b1220;padding:12px;border-radius:12px;box-shadow:0 6px 18px rgba(2,6,23,.6)}
    video{width:100%;height:auto;border-radius:8px;background:#000}
    canvas{position:absolute;left:0;top:0}
    .controls{display:flex;gap:8px;margin-top:8px}
    button{background:#0ea5a9;border:none;padding:8px 12px;border-radius:8px;color:#042027;cursor:pointer}
    .numbers{display:flex;flex-wrap:wrap;gap:8px}
    .num{width:60px;height:60px;border-radius:8px;background:#071627;display:flex;align-items:center;justify-content:center;font-size:20px}
    .num.chosen{background:#065f46}
    .log{font-family:monospace;font-size:13px;line-height:1.4;max-height:560px;overflow:auto}
    .status{margin-top:8px}
  </style>
</head>
<body>
  <h1>Mind-Reader Demo — Live Video + Face Tracking (JS + HTML)</h1>
  <div class="wrap">
    <div class="card">
      <div style="position:relative">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="overlay" width="640" height="480" style="position:absolute;right:0;top:0;pointer-events:none"></canvas>
      </div>
      <div class="controls">
        <button id="startCam">Start Camera</button>
        <button id="generate">Generate Numbers</button>
        <button id="begin" disabled>Begin Read</button>
      </div>
      <div class="status" id="status">Status: Idle</div>
    </div>

    <div class="card" style="padding:18px;">
      <h2 style="font-size:16px;margin-bottom:8px">Instructions (Hinglish, Devanagari)</h2>
      <p>1) <strong>Start Camera</strong> pe click karo aur apni face ko camera ke samne rakho.<br>
      2) <strong>Generate Numbers</strong> — screen pe 10 random numbers aayenge. Ek number socho (man se, bolna nahi).<br>
      3) <strong>Begin Read</strong> dabao — app numbers ko randomly ek-ek karke dikhayega aur face-movement track karega.<br>
      4) App heuristic use karke jiska face response maximum hua, woh number suggest karega. <em>(Note: ये 100% mind-reading नहीं — सिर्फ face-movement heuristic है)</em></p>

      <div style="margin-top:12px">
        <div id="numbersArea" class="numbers"></div>
      </div>

      <div style="margin-top:12px">
        <strong>Predicted:</strong> <span id="predicted">—</span>
      </div>
    </div>

    <div class="card">
      <h3 style="margin-top:0">Log / Live Data</h3>
      <div class="log" id="log"></div>
      <div style="margin-top:12px"><small>Note: This demo uses a simple gaze/head-movement heuristic. For robust production use, refine detection & thresholds.</small></div>
    </div>
  </div>

  <!-- libraries: TensorFlow.js + face-landmarks-detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.8.0/dist/tf-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.8.0/dist/tf-converter.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.8.0/dist/tf-backend-webgl.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.1/dist/face-landmarks-detection.min.js"></script>

  <script>
    // == Elements ==
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const startCamBtn = document.getElementById('startCam');
    const generateBtn = document.getElementById('generate');
    const beginBtn = document.getElementById('begin');

    const numbersArea = document.getElementById('numbersArea');
    const logEl = document.getElementById('log');
    const statusEl = document.getElementById('status');
    const predictedEl = document.getElementById('predicted');

    let model = null;
    let streaming = false;
    let numbers = [];
    let order = [];
    let readings = {}; // store score per number

    // Heuristic params
    const BASELINE_MS = 2000; // initial baseline capture time
    const SHOW_PER_NUMBER_MS = 1500; // how long each number shows
    const GAP_MS = 400; // gap between numbers
    const MOVEMENT_THRESHOLD = 0.015; // heuristic threshold

    async function startCamera(){
      try{
        const stream = await navigator.mediaDevices.getUserMedia({video:{width:640,height:480}, audio:false});
        video.srcObject = stream;
        await video.play();
        overlay.width = video.videoWidth || 640;
        overlay.height = video.videoHeight || 480;
        streaming = true;
        log('Camera started');
        status('Camera running — loading model...');

        // load model
        if(!model){
          model = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh, {runtime:'tfjs'});
          log('Face-landmarks model loaded');
        }

        status('Ready. Generate numbers.');
      }catch(err){
        log('Error starting camera: '+err.message);
        status('Camera error');
      }
    }

    startCamBtn.addEventListener('click', startCamera);

    generateBtn.addEventListener('click', ()=>{
      numbers = generateUniqueNumbers(10, 1, 99); // show 10 numbers between 1..99
      renderNumbers();
      beginBtn.disabled = false;
      predictedEl.textContent = '—';
      readings = {};
      log('Numbers generated: ' + numbers.join(', '));
      status('Numbers generated — think of one number silently.');
    });

    beginBtn.addEventListener('click', async ()=>{
      if(!streaming || !model){ alert('Start camera and load model first'); return; }
      await beginReadSequence();
    });

    function generateUniqueNumbers(count, min, max){
      const set = new Set();
      while(set.size < count){ set.add(Math.floor(Math.random()*(max-min+1))+min); }
      return Array.from(set);
    }

    function renderNumbers(){
      numbersArea.innerHTML = '';
      numbers.forEach(n=>{
        const d = document.createElement('div');
        d.className = 'num';
        d.textContent = n;
        d.dataset.value = n;
        numbersArea.appendChild(d);
      });
    }

    function log(msg){
      const t = new Date().toLocaleTimeString();
      logEl.innerHTML = `[${t}] ${msg}<br>` + logEl.innerHTML;
    }

    function status(txt){ statusEl.textContent = 'Status: ' + txt; }

    // Helper: draw keypoints
    function drawResults(predictions){
      ctx.clearRect(0,0,overlay.width, overlay.height);
      if(!predictions || predictions.length===0) return;
      predictions.forEach(pred=>{
        const keypoints = pred.scaledMesh;
        ctx.fillStyle = 'aqua';
        for(let i=0;i<keypoints.length;i+=2){
          const x = keypoints[i][0];
          const y = keypoints[i][1];
          ctx.fillRect(x-1,y-1,2,2);
        }
      });
    }

    // Compute a simple gaze vector / head-movement metric using landmarks
    function computeMovementMetric(landmarks){
      // landmarks: array of [x,y,z] points (468 points for mediapipe)
      // We'll use a few stable reference points: nose tip (1), left eye center (~33), right eye center (~263)
      // Approach: compute normalized vector between eyes and nose to approximate head direction.
      try{
        const nose = landmarks[1];
        const leftEye = landmarks[33];
        const rightEye = landmarks[263];
        const eyeMid = [(leftEye[0]+rightEye[0])/2, (leftEye[1]+rightEye[1])/2];
        // vector from eyeMid to nose
        const vx = nose[0]-eyeMid[0];
        const vy = nose[1]-eyeMid[1];
        // normalize by image size
        const nx = vx / overlay.width;
        const ny = vy / overlay.height;
        // magnitude
        const mag = Math.sqrt(nx*nx + ny*ny);
        return {nx, ny, mag};
      }catch(e){ return {nx:0,ny:0,mag:0}; }
    }

    // Capture baseline for user's neutral face
    async function captureBaseline(durationMs=BASELINE_MS){
      status('Capturing baseline — keep face neutral...');
      log('Capturing baseline for '+(durationMs/1000)+'s');
      const samples = [];
      const t0 = performance.now();
      while(performance.now()-t0 < durationMs){
        const preds = await model.estimateFaces({input:video, returnTensors:false, flipHorizontal:false});
        if(preds && preds.length>0){
          const m = computeMovementMetric(preds[0].scaledMesh);
          samples.push(m.mag);
        }
        await new Promise(r=>setTimeout(r,80));
      }
      const avg = samples.length? (samples.reduce((a,b)=>a+b,0)/samples.length) : 0;
      log('Baseline average magnitude: '+avg.toFixed(4));
      status('Baseline captured');
      return avg;
    }

    async function beginReadSequence(){
      beginBtn.disabled = true;
      generateBtn.disabled = true;
      startCamBtn.disabled = true;
      predictedEl.textContent = '—';
      readings = {};
      numbers.forEach(n=>readings[n]=0);

      // shuffle order
      order = numbers.slice().sort(()=>Math.random()-0.5);

      // baseline
      const baseline = await captureBaseline();

      status('Starting sequence — watch the numbers');
      log('Sequence order: ' + order.join(', '));

      // run loop: show each number for SHOW_PER_NUMBER_MS with small gap
      for(let i=0;i<order.length;i++){
        const num = order[i];
        highlightNumber(num);
        const score = await measureResponseForNumber(num, baseline, SHOW_PER_NUMBER_MS);
        readings[num] += score;
        log('Number '+num+' scored '+score.toFixed(4));
        unhighlightNumber(num);
        await new Promise(r=>setTimeout(r, GAP_MS));
      }

      // choose predicted highest
      const entries = Object.entries(readings);
      entries.sort((a,b)=>b[1]-a[1]);
      const [pred, val] = entries[0];
      predictedEl.textContent = pred + ' (score '+val.toFixed(4)+')';
      status('Done — prediction shown');
      log('Prediction: '+pred+' (scores: '+JSON.stringify(readings)+')');

      beginBtn.disabled = false;
      generateBtn.disabled = false;
      startCamBtn.disabled = false;
    }

    function highlightNumber(num){
      const nodes = numbersArea.querySelectorAll('.num');
      nodes.forEach(n=>{ if(Number(n.dataset.value)===num) n.classList.add('chosen'); });
    }
    function unhighlightNumber(num){
      const nodes = numbersArea.querySelectorAll('.num');
      nodes.forEach(n=>{ if(Number(n.dataset.value)===num) n.classList.remove('chosen'); });
    }

    async function measureResponseForNumber(num, baseline, durationMs){
      // Show number visually (already highlighted). While showing, sample metric and compute deviation from baseline.
      const samples = [];
      const t0 = performance.now();
      while(performance.now()-t0 < durationMs){
        const preds = await model.estimateFaces({input:video, returnTensors:false, flipHorizontal:false});
        drawResults(preds);
        if(preds && preds.length>0){
          const m = computeMovementMetric(preds[0].scaledMesh);
          samples.push(m.mag);
        }
        await new Promise(r=>setTimeout(r,70));
      }
      // compute average deviation
      const avg = samples.length? (samples.reduce((a,b)=>a+b,0)/samples.length) : 0;
      const deviation = Math.max(0, avg - baseline);
      // small smoothing / normalization
      const score = deviation; // directly use deviation as score
      return score;
    }

    // continuous drawing to overlay when camera running
    async function continuousLoop(){
      if(!streaming || !model) return;
      try{
        const preds = await model.estimateFaces({input:video, returnTensors:false, flipHorizontal:false});
        drawResults(preds);
      }catch(e){ /* ignore */ }
      requestAnimationFrame(continuousLoop);
    }

    // start continuous loop when model ready & video plays
    video.addEventListener('playing', ()=>{
      if(model) continuousLoop();
    });

    // Accessibility: keyboard shortcuts
    document.addEventListener('keydown', (e)=>{
      if(e.key==='g') generateBtn.click();
      if(e.key==='s') startCamBtn.click();
      if(e.key==='b') beginBtn.click();
    });

    // End of script
  </script>
</body>
</html>
