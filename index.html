<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Webcam Mood Detector</title>
  <style>
    body{
      font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial;
      margin:20px;background:#f5f7fa;color:#111;text-align:center
    }
    video,canvas{
      border-radius:10px;
      box-shadow:0 4px 20px rgba(0,0,0,0.1);
      max-width:100%;
    }
    #controls{
      margin-top:12px;
      display:flex;
      justify-content:center;
      flex-wrap:wrap;
      gap:8px
    }
    button{
      padding:8px 14px;
      border-radius:8px;
      border:1px solid #ccc;
      background:white;
      cursor:pointer;
      font-size:15px
    }
    button[disabled]{opacity:.5;cursor:not-allowed}
    #status{margin-top:8px;font-size:14px;color:#444}
    .mood-pill{
      display:inline-block;
      padding:6px 10px;
      border-radius:20px;
      background:#eef2ff;
      border:1px solid #cdd8ff;
      margin:3px
    }
  </style>
</head>
<body>
  <h1>😀 Webcam Mood Detector</h1>
  <p>Click <b>Open Camera</b> → <b>Start Detection</b> to see your mood live.</p>

  <div style="position:relative;display:inline-block;">
    <video id="video" autoplay muted playsinline width="640" height="480"></video>
    <canvas id="overlay" width="640" height="480"
            style="position:absolute;left:0;top:0;pointer-events:none;"></canvas>
  </div>

  <div id="controls">
    <button id="btnOpen">Open Camera</button>
    <button id="btnStart" disabled>Start Detection</button>
    <button id="btnStop" disabled>Stop</button>
  </div>

  <div id="status">Models not loaded</div>
  <div id="result"></div>

  <!-- Load face-api.js from CDN -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script>
    const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models/';
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const btnOpen = document.getElementById('btnOpen');
    const btnStart = document.getElementById('btnStart');
    const btnStop = document.getElementById('btnStop');
    const status = document.getElementById('status');
    const result = document.getElementById('result');
    let stream = null;
    let analyzing = false;
    let intervalId = null;

    async function loadModels(){
      status.textContent = 'Loading models...';
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
      ]);
      status.textContent = 'Models loaded ✔️';
      btnStart.disabled = false;
    }

    btnOpen.addEventListener('click', async ()=>{
      try{
        stream = await navigator.mediaDevices.getUserMedia({video:true});
        video.srcObject = stream;
        btnOpen.disabled = true;
        status.textContent = 'Camera open — loading models...';
        await loadModels();
      }catch(err){
        alert('Camera access failed: ' + err.message);
      }
    });

    function drawDetections(dets){
      ctx.clearRect(0,0,overlay.width,overlay.height);
      dets.forEach(det=>{
        const {x,y,width,height} = det.detection.box;
        ctx.strokeStyle='rgba(0,150,255,0.9)';
        ctx.lineWidth=2;
        ctx.strokeRect(x,y,width,height);
        const expr = det.expressions;
        const top = Object.entries(expr).sort((a,b)=>b[1]-a[1])[0];
        ctx.fillStyle='rgba(0,0,0,0.5)';
        ctx.fillRect(x,y-20,ctx.measureText(top[0]).width+40,18);
        ctx.fillStyle='white';
        ctx.font='14px sans-serif';
        ctx.fillText(top[0]+' '+(top[1]*100).toFixed(0)+'%',x+5,y-6);
      });
    }

    btnStart.addEventListener('click', ()=>{
      if(analyzing) return;
      analyzing=true;
      btnStart.disabled=true;
      btnStop.disabled=false;
      status.textContent='Analyzing...';
      intervalId=setInterval(async ()=>{
        const dets=await faceapi.detectAllFaces(video,new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
        drawDetections(dets);
        if(dets.length>0){
          const expr=dets[0].expressions;
          const top=Object.entries(expr).sort((a,b)=>b[1]-a[1])[0][0];
          result.innerHTML=`<div class='mood-pill'>Current mood: <b>${top}</b></div>`;
        }else{
          result.textContent='No face detected';
        }
      },250);
    });

    btnStop.addEventListener('click',()=>{
      analyzing=false;
      btnStop.disabled=true;
      btnStart.disabled=false;
      clearInterval(intervalId);
      ctx.clearRect(0,0,overlay.width,overlay.height);
      status.textContent='Stopped';
    });

    window.addEventListener('beforeunload',()=>{
      if(stream) stream.getTracks().forEach(t=>t.stop());
    });
  </script>
</body>
</html>
